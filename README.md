# DSA-Project-Group-5

---

# ğŸ§  MiniDB â€” Scalable In-Memory Data Management System

### *DS115 - Data Structures / Algorithms in Data Science*

### **Team:** DSA Group 5

---

## ğŸ¯ Objective

The goal of this project is to design and implement a **lightweight, scalable, in-memory database** capable of handling large datasets efficiently.
Our MiniDB supports:

* Search, insertion, deletion, modification, and range queries
* Graph-based relationships and traversal
* Analytical operations (min, max, average, top-K)
* Manual AVL Tree indexing for efficiency
* An interactive **Streamlit** UI

This project applies the core **data structures and algorithms** learned during the semester â€” especially **AVL Trees** and **Graph Algorithms** â€” to create a functional and efficient system.

---

## ğŸ“ Folder Structure

```
DSA-Project-Group-5/
â”‚
â”œâ”€â”€ main.py                         # Application entry point (launches Streamlit UI)
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ Project description.pdf         # Original project specification
â”‚
â”œâ”€â”€ data/                           # Steam dataset (CSV files)
â”‚   â”œâ”€â”€ applications.csv
â”‚   â”œâ”€â”€ application_categories.csv
â”‚   â”œâ”€â”€ application_developers.csv
â”‚   â”œâ”€â”€ application_genres.csv
â”‚   â”œâ”€â”€ application_platforms.csv
â”‚   â”œâ”€â”€ application_publishers.csv
â”‚   â”œâ”€â”€ categories.csv
â”‚   â”œâ”€â”€ developers.csv
â”‚   â”œâ”€â”€ genres.csv
â”‚   â”œâ”€â”€ platforms.csv
â”‚   â”œâ”€â”€ publishers.csv
â”‚   â””â”€â”€ reviews_final.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                    # Core storage and indexing layer
â”‚   â”‚   â”œâ”€â”€ avl_tree.py             # Manual AVL tree implementation
â”‚   â”‚   â”œâ”€â”€ data_store.py           # In-memory data store with AVL indexes
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ query_engine/               # CRUD operations and range queries
â”‚   â”‚   â”œâ”€â”€ query_handler.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                      # Graph-based features
â”‚   â”‚   â”œâ”€â”€ graph_model.py          # Adjacency-map graph implementation
â”‚   â”‚   â”œâ”€â”€ graph_algorithms.py     # BFS, DFS, shortest path, components
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                  # Analytics and querying UI components
â”‚   â”‚   â”œâ”€â”€ dataset_status.py       # Dataset loading overview
â”‚   â”‚   â”œâ”€â”€ indexed_engine.py       # Indexed query engine builder
â”‚   â”‚   â”œâ”€â”€ search_by_appid.py      # Indexed search by appid
â”‚   â”‚   â”œâ”€â”€ search_by_name.py       # Linear name search (subset)
â”‚   â”‚   â”œâ”€â”€ price_range.py          # AVL-based price range queries
â”‚   â”‚   â”œâ”€â”€ basic_analytics.py      # Min / max / avg / median statistics
â”‚   â”‚   â”œâ”€â”€ graph_explorer.py       # Graph exploration UI
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                         # Streamlit frontend
â”‚   â”‚   â”œâ”€â”€ app.py                  # Main Streamlit application
â”‚   â”‚   â”œâ”€â”€ graph_explorer.py       # Advanced graph UI (slice + full modes)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                      # Utilities and data loading
â”‚   â”‚   â”œâ”€â”€ data_loader.py          # CSV loader and cleaner (no pandas)
â”‚   â”‚   â”œâ”€â”€ schemas.py              # Dataset schemas and type definitions
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ test_storage.py             # Storage and AVL testing
â”‚
â””â”€â”€ .gitignore                      # Git ignore rules


---

## ğŸ’» Programming Languages & Libraries

**Primary Language:** Python 3.11+

**Libraries Used:**

* `streamlit` â€” interactive web-based user interface
* `os` â€” file system and path operations
* `sys` â€” Python path and runtime configuration
* `csv` â€” reading and parsing CSV dataset files
* `collections` â€” efficient data structures (deque, defaultdict)
* `statistics` â€” basic statistical calculations (e.g., median)
* `typing` â€” type annotations for clarity and maintainability

---

## ğŸ“Š Dataset

### Steam Dataset 2025 â€” Multi-Modal Gaming Analytics

ğŸ“¦ Source: [Kaggle Dataset Link](https://www.kaggle.com/datasets/crainbramp/steam-dataset-2025-multi-modal-gaming-analytics)

**Description:**

* ~239,000 Steam games and 1M+ user reviews
* Covers metadata, pricing, genres, ratings, platforms, and developerâ€“publisher networks
* 13 normalized relational tables (relational and graph-ready)
* Includes 1024-dimensional vector embeddings for semantic relationships

**Why we chose it:**

* Large-scale dataset (>1,000,000 records âœ…)
* Includes both **tabular** and **graph** structures (developer â†” publisher)
* Perfect for applying range queries, AVL indexing, and graph traversal algorithms

---

# âš™ï¸ Project Phases

---

## ğŸ”¹ **PHASE 1: Dataset Preparation**

### Step 1.1 â€” Select and Load Dataset

* Download dataset CSVs from Kaggle.
* Load into `/data` folder.
* Use `pandas` to load a manageable subset initially for testing (e.g., first 50,000 rows).

### Step 1.2 â€” Clean and Normalize Data

* Handle missing values, drop redundant columns.
* Ensure key attributes:
  `game_id`, `title`, `price`, `rating`, `genre`, `developer`, `publisher`, `release_year`.

### Step 1.3 â€” Store Raw Data

* Create a list of dictionaries:

  ```python
  [{"id": 1, "title": "Portal 2", "price": 9.99, "genre": "Puzzle", ...}, ...]
  ```
* This serves as the base layer for MiniDB.

ğŸ’¬ *Tip:* Start small for debugging. Use only a few thousand records until AVL and queries are stable.

---

## ğŸ”¹ **PHASE 2: Storage & Indexing Layer (AVL Tree)**

### Step 2.1 â€” Implement Manual AVL Tree

* Implement from scratch in `avl_tree.py`.
* Include: `insert()`, `delete()`, `search()`, and rotations (`LL`, `RR`, `LR`, `RL`).
* Keep balancing logic well-commented to demonstrate understanding.

### Step 2.2 â€” Integrate Index with Data Store

* In `data_store.py`, connect the raw dataset with AVL-based indexing.
* Example:

  ```python
  price_index = AVLTree()
  for record in data:
      price_index.insert(record["price"], record)
  ```
* This allows fast range queries and lookups by price or rating.

### Step 2.3 â€” Test AVL Tree

* Test insertion and deletion performance.
* Compare with linear search for validation.
* Print in-order traversal to verify balancing.

---

## ğŸ”¹ **PHASE 3: Query Engine**

### Step 3.1 â€” CRUD Operations

Implement core MiniDB functions in `query_handler.py`:

* `search_record(key)`
* `insert_record(record)`
* `delete_record(key)`
* `update_record(key, field, value)`

### Step 3.2 â€” Range Queries

* Use AVL traversal to retrieve all records between two values.

  ```python
  results = avl.range_query(min_price=10, max_price=30)
  ```
* Return results as lists of game entries.

### Step 3.3 â€” Performance Testing

* Use Pythonâ€™s `time` library to record operation time for each query type.
* Store results in `performance_analysis.md`.

---

## ğŸ”¹ PHASE 4: Graph Features

### **Step 4.1 â€” Graph Representation**

Use a custom graph implementation (no external libraries):
Nodes: Developers and Publishers
Edges: Collaboration between a developer and publisher if they worked on the same game
Edge weight: Number of shared games

### Step 4.2 â€” Implement Graph Algorithms

Implemented in graph_algorithms.py:
* `bfs_traversal(start_vertex)`
* `dfs_traversal(start_vertex)`
* `shortest_path(start_vertex, target_vertex)` (unweighted)
* `connected_components()` (collaboration clustering)

### Step 4.3 â€” Exploration (UI-Based)
*Graph exploration is done via a Streamlit interface:
  * Neighbor inspection
  * BFS / DFS traversal output
  * Connected component analysis
  * Large graphs are handled by operating on dataset subsets for performance.

## ğŸ”¹ **PHASE 5: Final Integration & UI**

### Step 5.1 â€” Build Streamlit UI

* File: `/src/ui/app.py`
* Allow users to:

  * Search by name, price, or rating
  * View range query results
  * Explore developerâ€“publisher connections
  * Display analytics (e.g., average rating by genre)

### Step 5.2 â€” Integrate Analytics

* In `analytics.py`, implement:

  * `min_price()`, `max_price()`, `avg_rating()`, `median_price()`, `top_k_games(k)`
  * Optional: `knn_similar_games(title)` using embeddings

### Step 5.3 â€” System Integration

* Connect all layers (Data â†’ AVL â†’ Query Engine â†’ Graph â†’ UI).
* Test all workflows end-to-end:

  1. Load dataset
  2. Build indexes
  3. Run search and graph queries
  4. View analytics in UI


---

## ğŸ§© Deliverables

âœ… Fully functional MiniDB system
âœ… `README.md` (this file)
âœ… Technical Report (2â€“4 pages)
âœ… Streamlit UI demo
âœ… Presentation

---

## ğŸ“˜ References

* Kaggle Steam Dataset 2025 â€” Multi-Modal Gaming Analytics
* AVL Tree algorithms (CLRS, GeeksforGeeks, and textbook references)
* Streamlit official docs

---
